{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 Person of Interest\n",
    "## A detection and tracking system for public cameras\n",
    "\n",
    "## Part II TensorFlow object detection system and combination with tracker\n",
    "\n",
    "## After training two deep learning models, combine tracker with object detection, to find the count of pedestrians in the video and their speed. \n",
    "\n",
    "Person of Interest: OpenCV Tracking API | TensorFlow | Deep learning | AWS\n",
    "- Enable the camera watch for public security at New York Time Square.\n",
    "- Developing a detection and tracking system for one of the public cameras.\n",
    "- Setting notification of abnormal counts of people and their moving speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find velocity of pedestrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find velocity of pedestrian\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "cv2.namedWindow(\"tracking\")\n",
    "camera = cv2.VideoCapture('../../../nyc17_ds12/projects/05-kojak/videos/less/media_w922939858_9.ts')\n",
    "ok, image=camera.read()\n",
    "if not ok:\n",
    "    print('Failed to read video')\n",
    "    exit()\n",
    "\n",
    "#bounding box, region of interest !!! #bbox=(x,y,w,h)  \n",
    "bbox = cv2.selectROI(\"tracking\", image)\n",
    "print(bbox)\n",
    "\n",
    "x0=int(bbox[0])\n",
    "y0=int(bbox[1])\n",
    "count=0\n",
    "ave_v=[]\n",
    "ave_vx=[]\n",
    "\n",
    "tracker_mil = cv2.TrackerMIL_create()\n",
    "init_once = False\n",
    "\n",
    "while camera.isOpened():\n",
    "    ok, image=camera.read()\n",
    "    if not ok:\n",
    "        print ('no image to read')\n",
    "        break\n",
    "\n",
    "    if not init_once:\n",
    "        ok = tracker_mil.init(image,bbox)\n",
    "        if not ok:\n",
    "            print ('tracker %i init error' % i)\n",
    "            break\n",
    "        init_once = True\n",
    "\n",
    "    ok, newbox = tracker_mil.update(image)\n",
    "\n",
    "    if ok:\n",
    "        p1=(int(newbox[0]),int(newbox[1]))\n",
    "        p2=(int(newbox[0]+newbox[2]),int(newbox[1]+newbox[3]))\n",
    "        cv2.rectangle(image,p1,p2,(0,200,0),2)\n",
    "\n",
    "        x=int(newbox[0])\n",
    "        y=int(newbox[1])\n",
    "        \n",
    "        if count == 10:\n",
    "            update_v(sum(ave_v)/10)\n",
    "            update_v(sum(ave_vx)/10)\n",
    "            #reset velocity list and count\n",
    "            count=1\n",
    "            ave_v=[np.sqrt((x-x0)**2 + (y-y0)**2)]\n",
    "            ave_vx=[x-x0]\n",
    "        else:\n",
    "            ave_v.append(np.sqrt((x-x0)**2 + (y-y0)**2))\n",
    "            ave_vx.append(x-x0)            \n",
    "            count+=1\n",
    "\n",
    "        x0 = x\n",
    "        y0 = y\n",
    "\n",
    "    cv2.imshow(\"tracking\", image)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 : break # esc pressed\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "MODEL_NAME = 'pedestrian_graph_aws5'\n",
    "# MODEL_NAME = 'pedestrian_graph_aws_rcnn'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('training', 'pedestrian_label_lessclass.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_objects(image_np,sess,detection_graph):\n",
    "    #get image width and height from shape\n",
    "    w=image_np.shape[1]\n",
    "    h=image_np.shape[0]\n",
    "        \n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    \n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    \n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num_detections) = sess.run(  \n",
    "          [boxes, scores, classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "    squeezed_boxes = np.squeeze(boxes)\n",
    "    \n",
    "    i=0\n",
    "    while scores[0][i]>=0.5:\n",
    "        i+=1\n",
    "    \n",
    "    bboxes=[]\n",
    "    for j in range(i):\n",
    "        y = int(h*boxes[0][j][0])\n",
    "        x = int(w*boxes[0][j][1])\n",
    "        hy = int(h*(boxes[0][j][2]-boxes[0][j][0]))\n",
    "        wx = int(w*(boxes[0][j][3]-boxes[0][j][1]))\n",
    "        bboxes.append((x,y,wx,hy))\n",
    "    return bboxes, classes[0][:i], scores[0][:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def update_v(v):\n",
    "    print(v) \n",
    "    return\n",
    "\n",
    "def reset_tracker(image_np,sess,detection_graph):\n",
    "    bboxes, classes, scores = detect_objects(image_np,sess,detection_graph)\n",
    "    # set/reset multiple tracker\n",
    "    tracker = cv2.MultiTracker_create()\n",
    "    for i in range(len(bboxes)):\n",
    "        tracker.add(cv2.TrackerMIL_create(), image_np, bboxes[i])\n",
    "    \n",
    "    return tracker, classes, scores\n",
    "\n",
    "def draw_object_boxes(boxes,image_np):\n",
    "    for i in range(len(boxes)):\n",
    "        p1 = (int(boxes[i][0]), int(boxes[i][1]))\n",
    "        p2 = (int(boxes[i][0] + boxes[i][2]), int(boxes[i][1] + boxes[i][3]))\n",
    "        cv2.rectangle(image_np, p1, p2, (0,200,0),2)\n",
    "\n",
    "    return image_np\n",
    "\n",
    "def cal_avg_speed_list(speed_lists):\n",
    "    if len(speed_lists) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        return [sum(l) / len(l) for l in speed_lists]\n",
    "\n",
    "def reset_positions(boxes):\n",
    "    return [(int(box[0]), int(box[1])) for box in boxes]\n",
    "\n",
    "def reset_speed_lists(dim):\n",
    "    return [[] for i in range(dim)]\n",
    "\n",
    "def update_speed_lists(boxes, x_speed_lists, xy_speed_lists,positions):\n",
    "    n = len(x_speed_lists)\n",
    "    if n != len(boxes):\n",
    "        print(\"Error: speed list length and boxes number not match\")\n",
    "        exit()\n",
    "    elif n != len(positions):\n",
    "        print(\"Error: speed list length and positions number not match\")\n",
    "        exit()\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            x0 = positions[i][1]\n",
    "            x1 = int(boxes[i][1])\n",
    "            y0 = positions[i][0]\n",
    "            y1 = int(boxes[i][0])\n",
    "            xy_speed_lists[i].append(np.sqrt((x1-x0)**2 + (y1-y0)**2))\n",
    "            x_speed_lists[i].append(x1-x0)\n",
    "            positions[i] = [y1,x1]\n",
    "            \n",
    "    return (x_speed_lists, xy_speed_lists, positions)\n",
    "    \n",
    "#\n",
    "cv2.namedWindow(\"tracking\")\n",
    "cap = cv2.VideoCapture('../../../nyc17_ds12/projects/05-kojak/videos/less/n11.mov')\n",
    "#n14, for ssd -2000 model\n",
    "#run0 for ssd -10000 model\n",
    "\n",
    "# Initialize variables\n",
    "counter = 0\n",
    "# i=0\n",
    "x_speed_lists = []\n",
    "xy_speed_lists = []\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        while(cap.isOpened()):\n",
    "            # read frame\n",
    "            ret,image_np = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # detecting every 10 frames\n",
    "            if counter%10 == 0:\n",
    "                # set/reset multiple tracker & counter\n",
    "                tracker, classes, scores = reset_tracker(image_np, sess, detection_graph)\n",
    "                counter = 0\n",
    "            \n",
    "            # tracking: update object boxes\n",
    "            ok, boxes = tracker.update(image_np)\n",
    "\n",
    "            # tracking: draw object boxes\n",
    "            image_np = draw_object_boxes(boxes, image_np)\n",
    "            \n",
    "            # tracking: update average speed list\n",
    "            if counter == 0:\n",
    "                x_avg_speed_list = cal_avg_speed_list(x_speed_lists)\n",
    "                xy_avg_speed_list = cal_avg_speed_list(xy_speed_lists)\n",
    "                \n",
    "                positions = reset_positions(boxes)\n",
    "                x_speed_lists = reset_speed_lists(len(boxes))\n",
    "                xy_speed_lists = reset_speed_lists(len(boxes))\n",
    "            else:\n",
    "                x_speed_lists, xy_speed_lists, positions = update_speed_lists(boxes, x_speed_lists, xy_speed_lists, positions)\n",
    "            \n",
    "#             print(len(boxes),'\\n')\n",
    "#             print(boxes)\n",
    "#             print(x_avg_speed_list,xy_avg_speed_list)\n",
    "#             break\n",
    "            \n",
    "#             vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#                   image_np,\n",
    "#                   np.squeeze(boxes),\n",
    "#                   np.squeeze(classes).astype(np.int32),\n",
    "#                   np.squeeze(scores),\n",
    "#                   {},\n",
    "#                   use_normalized_coordinates=True,\n",
    "#                   line_thickness=8)\n",
    "            \n",
    "            # increment counter\n",
    "            counter += 1\n",
    "#             i += 1\n",
    "#             cv2.putText(img, 'Tian',(x,y),font,4,(100,100,0),4,cv2.LINE_AA)\n",
    "\n",
    "            # show marked frame\n",
    "            cv2.imshow('tracking', image_np)\n",
    "#             cv2.imwrite( \"../../../nyc17_ds12/projects/05-kojak/images/flask_display/n14_101136_%d.jpg\" %i, image_np );\n",
    "            if cv2.waitKey(25) & 0xff == 27:\n",
    "                break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1,5):\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
